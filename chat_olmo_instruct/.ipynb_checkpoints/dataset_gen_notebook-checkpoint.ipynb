{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57955b0b-2c8a-48b5-b688-24c42008ad4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import json\n",
    "import mlflow\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a38de9-8ac0-499a-b172-46c00a49997e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('lmsys/lmsys-chat-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3a9b0a-9a64-4858-a837-d2df61371341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation_id', 'model', 'conversation', 'turn', 'language', 'openai_moderation', 'redacted'],\n",
       "        num_rows: 1000000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8f5692-5d5a-44a9-b2b9-d1d9ce13c75d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_id': '6667fbe9c4854e9292a49861c5d16f9d',\n",
       " 'model': 'llama-2-13b-chat',\n",
       " 'conversation': [{'content': 'ПРИВЕТ', 'role': 'user'},\n",
       "  {'content': \"Привет! Hello! It's nice to meet you. I'm here to help answer any questions you may have, while being safe, respectful, and honest. I strive to provide socially unbiased and positive responses that are free of harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. If a question doesn't make sense or is not factually coherent, I will do my best to explain why instead of providing an incorrect answer. If I don't know the answer to a question, I will be honest and say so. Please feel free to ask me anything!\",\n",
       "   'role': 'assistant'}],\n",
       " 'turn': 1,\n",
       " 'language': 'Russian',\n",
       " 'openai_moderation': [{'categories': {'harassment': False,\n",
       "    'harassment/threatening': False,\n",
       "    'hate': False,\n",
       "    'hate/threatening': False,\n",
       "    'self-harm': False,\n",
       "    'self-harm/instructions': False,\n",
       "    'self-harm/intent': False,\n",
       "    'sexual': False,\n",
       "    'sexual/minors': False,\n",
       "    'violence': False,\n",
       "    'violence/graphic': False},\n",
       "   'category_scores': {'harassment': 0.00030283537,\n",
       "    'harassment/threatening': 4.8082005e-05,\n",
       "    'hate': 0.001146953,\n",
       "    'hate/threatening': 0.00057943224,\n",
       "    'self-harm': 4.109301e-05,\n",
       "    'self-harm/instructions': 4.2262967e-05,\n",
       "    'self-harm/intent': 3.9282415e-05,\n",
       "    'sexual': 0.0019007464,\n",
       "    'sexual/minors': 0.0002603775,\n",
       "    'violence': 0.0010673775,\n",
       "    'violence/graphic': 0.0004498428},\n",
       "   'flagged': False},\n",
       "  {'categories': {'harassment': False,\n",
       "    'harassment/threatening': False,\n",
       "    'hate': False,\n",
       "    'hate/threatening': False,\n",
       "    'self-harm': False,\n",
       "    'self-harm/instructions': False,\n",
       "    'self-harm/intent': False,\n",
       "    'sexual': False,\n",
       "    'sexual/minors': False,\n",
       "    'violence': False,\n",
       "    'violence/graphic': False},\n",
       "   'category_scores': {'harassment': 4.9643627e-06,\n",
       "    'harassment/threatening': 4.240044e-09,\n",
       "    'hate': 1.180996e-07,\n",
       "    'hate/threatening': 1.14717576e-10,\n",
       "    'self-harm': 4.769856e-09,\n",
       "    'self-harm/instructions': 1.33582185e-08,\n",
       "    'self-harm/intent': 1.6668768e-08,\n",
       "    'sexual': 0.00023611488,\n",
       "    'sexual/minors': 3.5049024e-07,\n",
       "    'violence': 3.6026875e-06,\n",
       "    'violence/graphic': 2.0791756e-08},\n",
       "   'flagged': False}],\n",
       " 'redacted': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc7c335-9811-4175-b287-92dbbd3fa5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce34548a6eff45e98d72751eb5ca2816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/1000000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda conv: conv['language'] == 'English', num_proc=4) # filtering all the other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84193e61-34e2-4f00-8315-c47779c45ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cols = [key for key in dict(dataset['train'][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5478e7c5-5e7c-47e5-9ae1-c15155bf5f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conversation_id',\n",
       " 'model',\n",
       " 'conversation',\n",
       " 'turn',\n",
       " 'language',\n",
       " 'openai_moderation',\n",
       " 'redacted']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c8db4-f464-440f-9672-2f9f5b6502a9",
   "metadata": {},
   "source": [
    "## Format according to ChatML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa63f993-175f-40a7-9a29-4e68008f1303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import hf_olmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9baaa3-831c-467c-994e-08505ddd3117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ckpt = \"allenai/OLMo-1B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "204ce2c3-778d-4cee-a6b5-d1b5a5c6b25e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f1930e-23f0-4e24-ab2d-c4e3de4345e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "395db7fa-2937-4bef-8dd8-52ea412466d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No chat template is defined for this tokenizer - using a default chat template that implements the ChatML format (without BOS/EOS tokens!). If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.default_chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "923d8792-26f8-44d6-b8a9-db1b8c03e055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>user\\nhow can identity protection services help protect me against identity theft<|im_end|>\\n<|im_start|>assistant\\nIdentity protection services can help protect you against identity theft in several ways:\\n\\n1. Monitoring: Many identity protection services monitor your credit reports, public records, and other sources for signs of identity theft. If they detect any suspicious activity, they will alert you so you can take action.\\n2. Credit freeze: Some identity protection services can help you freeze your credit, which makes it more difficult for thieves to open new accounts in your name.\\n3. Identity theft insurance: Some identity protection services offer insurance that can help you recover financially if you become a victim of identity theft.\\n4. Assistance: Many identity protection services offer assistance if you become a victim of identity theft. They can help you file a police report, contact credit bureaus, and other steps to help you restore your identity.\\n\\nOverall, identity protection services can provide you with peace of mind and help you take proactive steps to protect your identity. However, it's important to note that no service can completely guarantee that you will never become a victim of identity theft. It's still important to take steps to protect your own identity, such as being cautious with personal information and regularly monitoring your credit reports.<|im_end|>\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(dataset['train'][0]['conversation'], tokenize=False, add_generation_prompt=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175b961-a61d-4ba7-bd12-87f511bc28cb",
   "metadata": {},
   "source": [
    "## adding tokens to OLMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5045caf5-8ba8-4dd9-8b34-4b925ac63bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\"<|im_start|>\", \"<|im_end|>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a4865b-9839-475f-bc9c-f444a929e32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f921e7-4160-4cb2-940b-23292baaf8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chat(ex):\n",
    "   \n",
    "    chat = ex['conversation']\n",
    "    \n",
    "    formatted_chat = tokenizer.apply_chat_template(\n",
    "        chat,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False,\n",
    "    )+ tokenizer.eos_token \n",
    "    \n",
    "    tokenized_output = tokenizer(\n",
    "            formatted_chat,\n",
    "            add_special_tokens = False,\n",
    "            padding=\"max_length\",\n",
    "            max_length=1024,\n",
    "            truncation=True\n",
    "    )\n",
    "    \n",
    "    return tokenized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467d1b0-55ce-463c-a392-f28ee50e60f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "217bffe8-102a-460e-84a3-53ddeb4102b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422c785b4a144d3fb82cc9984d965301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/777453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmsys_tokenized = dataset.map(format_chat, num_proc=16).remove_columns(dict_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb04c8e2-320e-4e98-a728-30fc848f2296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 777453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmsys_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9fe65c2-f9e9-41fc-a6f3-8e95d76bc2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator= DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ec4c1a7-61a1-4cbd-890c-4ede7630ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(123)\n",
    "\n",
    "olmo_tokenized_split = lmsys_tokenized[\"train\"].train_test_split(\n",
    "    train_size=60000, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41116e59-6e64-4276-afc4-5034c26f6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MLFLOW_EXPERIMENT_NAME=fraud-detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5d7c499-f6b1-4f74-89c1-498343d37a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment 'olmo1b_chat' with id 701987021258002861\n"
     ]
    }
   ],
   "source": [
    "!mlflow experiments create --experiment-name olmo1b_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3208e2d5-bb96-45ad-9a7c-e139984e8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_tracking_path = os.path.join('../mlflow_results', 'olmo_orcaslim_instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "300e1066-cced-40dd-8017-6e88c0190e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(mlflow_tracking_path):\n",
    "    os.mkdir(mlflow_tracking_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdca36b8-4144-4043-a371-b3b38ae222ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join(mlflow_tracking_path, 'output')\n",
    "LOG_DIR = os.path.join(mlflow_tracking_path, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a95707dd-876f-44a5-8cfa-e04de5e19d7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainingArguments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mOUTPUT_DIR,\n\u001b[1;32m      3\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      4\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      5\u001b[0m     per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m      6\u001b[0m     auto_find_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     gradient_accumulation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      8\u001b[0m     warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      9\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     10\u001b[0m     logging_dir\u001b[38;5;241m=\u001b[39mLOG_DIR,\n\u001b[1;32m     11\u001b[0m     logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,  \u001b[38;5;66;03m# Log every 5 steps\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     lr_scheduler_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     bf16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m     gradient_checkpointing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m     save_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     17\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrainingArguments' is not defined"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=4,\n",
    "    auto_find_batch_size=True,\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=LOG_DIR,\n",
    "    logging_steps=5,  # Log every 5 steps\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=False,\n",
    "    save_steps=1000,\n",
    "    learning_rate=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a7c4d-6cd9-403b-aa01-949b9d086b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
